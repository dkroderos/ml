{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5824dc-de77-4276-8f23-6f1d6d526da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Rescaling, \n",
    "                                     Resizing, Dropout, RandomRotation, RandomContrast, RandomFlip)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.regularizers  import L2, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05f6a7-cab4-4fbb-a6ac-53d8e82625b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of GPUs available: ', len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('Test is built with CUDA: ', tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a07a81-d640-463c-8e61-2d2764689afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = './dataset/Emotions Dataset/Emotions Dataset/train'\n",
    "val_directory = './dataset/Emotions Dataset/Emotions Dataset/test'\n",
    "\n",
    "CLASS_NAMES = ['angry', 'happy', 'sad']\n",
    "\n",
    "CONFIGURATION = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'IM_SIZE': 256,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'N_EPOCHS': 20,\n",
    "    'DROPOUT_RATE': 0.0,\n",
    "    'REGULARIZATION_RATE': 0.0,\n",
    "    'N_FILTERS': 6,\n",
    "    'KERNEL_SIZE': 3,\n",
    "    'N_STRIDES': 1,\n",
    "    'POOL_SIZE': 2,\n",
    "    'N_DENSE_1': 100,\n",
    "    'N_DENSE_2': 10,\n",
    "    'NUM_CLASSES': 3,\n",
    "}\n",
    "\n",
    "CONFIGURATION = {\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"IM_SIZE\": 256,\n",
    "    \"LEARNING_RATE\": 1e-3,\n",
    "    \"N_EPOCHS\": 20,\n",
    "    \"DROPOUT_RATE\": 0.0,\n",
    "    \"REGULARIZATION_RATE\": 0.0,\n",
    "    \"N_FILTERS\": 6,\n",
    "    \"KERNEL_SIZE\": 3,\n",
    "    \"N_STRIDES\": 1,\n",
    "    \"POOL_SIZE\": 2,\n",
    "    \"N_DENSE_1\": 1024,\n",
    "    \"N_DENSE_2\": 128,\n",
    "    \"NUM_CLASSES\": 3,\n",
    "    \"PATCH_SIZE\": 16,\n",
    "    \"PROJ_DIM\": 768,\n",
    "    \"CLASS_NAMES\": [\"angry\", \"happy\", \"sad\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb8ec5-0cf2-48dc-9ced-54b9bf47886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    shuffle=True,\n",
    "    seed=99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8bbb0-cc47-4121-8970-7eb3ab341cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=val_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION['BATCH_SIZE'],\n",
    "    image_size=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    shuffle=True,\n",
    "    seed=99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87a997-5ad9-44d5-8cb3-ccf42fe7ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055619c4-492c-4f32-b4b4-d87c52b77616",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6e1f8-1833-48bc-aa17-3062ceb0c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(15):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i]/255.0)\n",
    "        plt.title(CLASS_NAMES[tf.argmax(labels[i], axis=0).numpy()])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac95f43-8211-4ab9-9de4-0c2c4a6549db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    for i in range(15):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i]/255.0)\n",
    "        plt.title(CLASS_NAMES[tf.argmax(labels[i], axis=0).numpy()])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a22fc4-2d76-41df-a736-f9029b1ff055",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_layers = tf.keras.Sequential([\n",
    "    RandomRotation(factor=(-0.025, 0.025),),\n",
    "    RandomFlip(mode='horizontal',),\n",
    "    RandomContrast(factor=0.1,),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e646b-ee05-4f4f-a56b-a6ff7f195b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_layer(image, label):\n",
    "    return augment_layers(image, training=True), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255abc4-dc95-4af2-b19e-0d54b1574e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box(lambda):\n",
    "    r_x = tf.cast(tfp.distributions.Uniform(0, CONFIGURATION['IM_SIZE']).sample(1)[0], dtype=tf.int32)\n",
    "    r_y = tf.cast(tfp.distributions.Uniform(0, CONFIGURATION['IM_SIZE']).sample(1)[0], dtype-tf.int32)\n",
    "\n",
    "    r_w = tf.cast(CONFIGURATION['IM_SIZE'] * tf.math.sqrt(1 - lambda), dtype=tf.int32)\n",
    "    r_h = tf.cast(CONFIGURATION['IM_SIZE'] * tf.math.sqrt(1 - lambda), dtype=tf.int32)\n",
    "\n",
    "    r_x = tf.clip_by_value(r_x - r_w / 2, 0, CONFIGURATION['IM_SIZE'])\n",
    "    r_y = tf.clip_by_value(r_y - r_h / 2, 0, CONFIGURATION['IM_SIZE'])\n",
    "\n",
    "    x_b_r = tf.clip_by_value(r_x + r_w / 2, 0 CONFIGURATION['IM_SIZE'])\n",
    "    y_b_r = tf.clip_by_value(r_y + r_h / 2, 0, CONFIGURATION['IM_SIZE'])\n",
    "\n",
    "    r_w = x_b_r - r_x\n",
    "    if (r_w == 0):\n",
    "        r_w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72717042-bf0c-4787-b326-ecf707820467",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    train_dataset\n",
    "    .map(augment_layer, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63165a1b-57b1-4648-b4a6-2b761e71093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = (\n",
    "    val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0da0c-9c02-471a-8522-5aa7e00927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for images, labels in training_dataset.take(1):\n",
    "    for i in range(15):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i]/255.0)\n",
    "        plt.title(CLASS_NAMES[tf.argmax(labels[i], axis=0).numpy()])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0355d-5486-4b6f-bd04-1737bbdc6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_rescale_layers = tf.keras.Sequential([\n",
    "    Resizing(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE']),\n",
    "    Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbfb2cc-5faa-4f40-a10e-e1757770e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(None, None, 3), ),\n",
    "\n",
    "    # InputLayer(input_shape=(CONFIGURATION['IM_SIZE'], CONFIGURATION['IM_SIZE'], 3)),\n",
    "    # Rescaling(1./255, name='rescaling'),\n",
    "\n",
    "    resize_rescale_layers,\n",
    "\n",
    "    Conv2D(filters=CONFIGURATION['N_FILTERS'],\n",
    "           kernel_size=CONFIGURATION['KERNEL_SIZE'],\n",
    "           strides=CONFIGURATION['N_STRIDES'],\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           kernel_regularizer=L2(CONFIGURATION['REGULARIZATION_RATE'])),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=CONFIGURATION['POOL_SIZE'],\n",
    "              strides=CONFIGURATION['N_STRIDES'] * 2),\n",
    "    Dropout(rate=CONFIGURATION['DROPOUT_RATE']),\n",
    "\n",
    "    Conv2D(filters=CONFIGURATION['N_FILTERS'],\n",
    "           kernel_size=CONFIGURATION['KERNEL_SIZE'],\n",
    "           strides=CONFIGURATION['N_STRIDES'],\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           kernel_regularizer=L2(CONFIGURATION['REGULARIZATION_RATE'])),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=CONFIGURATION['POOL_SIZE'],\n",
    "              strides=CONFIGURATION['N_STRIDES'] * 2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(CONFIGURATION['N_DENSE_1'],\n",
    "          activation='relu',\n",
    "          kernel_regularizer=L2(CONFIGURATION['REGULARIZATION_RATE'])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=CONFIGURATION['DROPOUT_RATE']),\n",
    "\n",
    "    Dense(CONFIGURATION['N_DENSE_2'], \n",
    "          activation='relu',\n",
    "          kernel_regularizer=L2(CONFIGURATION['REGULARIZATION_RATE'])),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(CONFIGURATION['NUM_CLASSES'],\n",
    "          activation='softmax'),\n",
    "])\n",
    "\n",
    "lenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7f29-ffb5-44d6-82ae-aa3ca822096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff89573-b23c-4826-bdd7-0885414838eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [CategoricalAccuracy(name='accuracy'), TopKCategoricalAccuracy(k=2, name='top_k_accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf255b-b967-43a4-9733-8176b3bf89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIGURATION['LEARNING_RATE']),\n",
    "    loss=loss_function,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91204144-671d-482c-baa4-cfd777149b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lenet_model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=CONFIGURATION['N_EPOCHS'],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d405fb-1261-41c2-9776-30ced9a2cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.save('./HumanEmotions.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be571ff1-10c3-47a8-b390-dfd7ee30140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model = tf.keras.models.load_model('./HumanEmotions.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561bbe3-d865-4e4e-93d8-2e038cd1a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edb7a9-eabe-4789-a8b8-432fb0408f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fada7f8-7f07-409b-8285-5f961c071a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad96a9-0ac0-4ab9-a35a-50b71d49160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_image = cv2.imread('./dataset/Emotions Dataset/Emotions Dataset/test/happy/707302.jpg')\n",
    "happy_im = tf.constant(happy_image, dtype=tf.float32)\n",
    "\n",
    "happy_im = tf.expand_dims(happy_im, axis=0)\n",
    "\n",
    "print(CLASS_NAMES[tf.argmax(lenet_model(happy_im), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e417f-6998-4729-a522-5f4fbe4fc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_image = cv2.imread('./dataset/Emotions Dataset/Emotions Dataset/test/sad/99675.jpg')\n",
    "sad_im = tf.constant(sad_image, dtype=tf.float32)\n",
    "\n",
    "sad_im = tf.expand_dims(sad_im, axis=0)\n",
    "\n",
    "print(CLASS_NAMES[tf.argmax(lenet_model(sad_im), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234b273-2b33-4b5b-be31-a8658e78205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    for i in range(15):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i]/255.0)\n",
    "        plt.title('True Label - : ' + CLASS_NAMES[tf.argmax(labels[i], axis=0).numpy()] + '\\n' + \n",
    "                  'Predicted Label - : ' + CLASS_NAMES[tf.argmax(lenet_model(tf.expand_dims(images[i], axis=0)), axis=-1).numpy()[0]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077321f6-1e9e-48c0-a916-0a390f473b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_img = cv2.imread('./neo.jpg')\n",
    "neo = tf.constant(neo_img, dtype=tf.float32)\n",
    "neo = tf.expand_dims(neo, axis=0)\n",
    "print(CLASS_NAMES[tf.argmax(lenet_model(neo), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ebc3b-8fa9-4eb1-822a-391513e32610",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(neo_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('True Label - : sad\\n' + \n",
    "          'Predicted Label - : ' + CLASS_NAMES[tf.argmax(lenet_model(neo), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd133385-c925-47e1-8b63-6af5d467de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_img = cv2.imread('./try.jpg')\n",
    "trythis = tf.constant(try_img, dtype=tf.float32)\n",
    "trythis = tf.expand_dims(trythis, axis=0)\n",
    "print(CLASS_NAMES[tf.argmax(lenet_model(trythis), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61894c90-b1d0-45d9-b09e-a27103648834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(try_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('True Label - : happy\\n' + \n",
    "          'Predicted Label - : ' + CLASS_NAMES[tf.argmax(lenet_model(trythis), axis=-1).numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48c93d-2338-4d03-a7ef-08fe66bc5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "labels = []\n",
    "\n",
    "for im, label in validation_dataset:\n",
    "    predicted.append(lenet_model(im))\n",
    "    labels.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784148e-4481-456e-b3af-79ab73ee84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.concatenate([np.argmax(labels[:-1], axis=-1).flatten(), np.argmax(labels[-1], axis=-1).flatten()]))\n",
    "print(np.concatenate([np.argmax(predicted[:-1], axis=-1).flatten(), np.argmax(labels[-1], axis=-1).flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933b78d-9d1f-45b8-a7cd-5b6ef3185bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate([np.argmax(labels[:-1], axis=-1).flatten(), np.argmax(labels[-1], axis=-1).flatten()])\n",
    "lab = np.concatenate([np.argmax(predicted[:-1], axis=-1).flatten(), np.argmax(labels[-1], axis=-1).flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f8ba7-4a4f-4bff-81e5-85691b895e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(lab, pred)\n",
    "print(cm)\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "sns.heatmap(cm, annot=True,)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e144636-b4e2-4bd4-9295-9e23132e9a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
